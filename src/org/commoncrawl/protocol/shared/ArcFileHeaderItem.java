// File generated by rpc compiler. Do not edit.

package org.commoncrawl.protocol.shared;

import java.io.DataInput;
import java.io.DataOutput;
import java.util.BitSet;
import java.io.IOException;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.record.Buffer;
import org.commoncrawl.util.shared.FlexBuffer;
import org.commoncrawl.util.shared.TextBytes;
import org.commoncrawl.util.shared.MurmurHash;
import org.commoncrawl.util.shared.ImmutableBuffer;
import org.commoncrawl.rpc.base.shared.BinaryProtocol;
import org.apache.hadoop.util.ReflectionUtils;
import org.apache.hadoop.conf.Configuration;
// Generated File: ArcFileHeaderItem
public class ArcFileHeaderItem extends org.commoncrawl.rpc.base.shared.RPCStruct  implements Writable{
  
  // optimized constructor helper 
  public static ArcFileHeaderItem newInstance(Configuration conf) {
      return ReflectionUtils.newInstance(ArcFileHeaderItem.class,conf);
  }
  // Writable Implementation
  public void write(DataOutput out) throws IOException{ 
    this.serialize(out,new BinaryProtocol());
  }
  
  public void readFields(DataInput  in) throws IOException{ 
    this.deserialize(in,new BinaryProtocol());
  }
  
  
  // Field Constants
  public static final int Field_ITEMKEY = 1;
  public static final int Field_ITEMVALUE = 2;
  static final int FieldID_MAX=Field_ITEMVALUE;
  
  // Field Declarations
  private BitSet __validFields = new BitSet(FieldID_MAX+1);
  
  private TextBytes itemKey=  new TextBytes();
  private TextBytes itemValue=  new TextBytes();
  
  // Default Constructor
  public ArcFileHeaderItem() { }
  
  // Accessors
  
  public final boolean isFieldDirty(int fieldId) { return __validFields.get(fieldId); }
  public final void setFieldDirty(int fieldId) { __validFields.set(fieldId); }
  
  public final void setFieldClean(int fieldId) { __validFields.clear(fieldId); }
  
  public TextBytes getItemKeyAsTextBytes() {
    return itemKey;
  }
  public String getItemKey() {
    return itemKey.toString();
  }
  public void setItemKey( String itemKey) {
    __validFields.set(Field_ITEMKEY);
    this.itemKey.set(itemKey);
  }
  public TextBytes getItemValueAsTextBytes() {
    return itemValue;
  }
  public String getItemValue() {
    return itemValue.toString();
  }
  public void setItemValue( String itemValue) {
    __validFields.set(Field_ITEMVALUE);
    this.itemValue.set(itemValue);
  }
  // Object Dirty support 
  
  public final boolean isObjectDirty(){
    boolean isDirty = !__validFields.isEmpty();
    return isDirty;
  }
  
  // serialize implementation 
  public final void serialize(DataOutput output,BinaryProtocol encoder)
  throws java.io.IOException {
    encoder.beginFields(output);
    // serialize field:itemKey
    if (__validFields.get(Field_ITEMKEY)){
      encoder.beginField(output,"itemKey",Field_ITEMKEY);
      encoder.writeTextBytes(output,itemKey);
    }
    // serialize field:itemValue
    if (__validFields.get(Field_ITEMVALUE)){
      encoder.beginField(output,"itemValue",Field_ITEMVALUE);
      encoder.writeTextBytes(output,itemValue);
    }
    encoder.endFields(output);
  }
  // deserialize implementation 
  public final void deserialize(DataInput input, BinaryProtocol decoder)
  throws java.io.IOException {
    // clear existing data first  
    clear();
    
    // reset protocol object to unknown field id enconding mode (for compatibility)
    decoder.pushFieldIdEncodingMode(BinaryProtocol.FIELD_ID_ENCODING_MODE_UNKNOWN);
    // keep reading fields until terminator (-1) is located 
    int fieldId;
    while ((fieldId = decoder.readFieldId(input)) != -1) { 
      switch (fieldId) { 
        case Field_ITEMKEY:{
          __validFields.set(Field_ITEMKEY);
          decoder.readTextBytes(input,itemKey);
        }
        break;
        case Field_ITEMVALUE:{
          __validFields.set(Field_ITEMVALUE);
          decoder.readTextBytes(input,itemValue);
        }
        break;
      }
    }
    // pop extra encoding mode off of stack 
    decoder.popFieldIdEncodingMode();
  }
  // clear implementation 
  public final void clear() {
    __validFields.clear();
    itemKey.clear();
    itemValue.clear();
  }
  // equals implementation 
  public final boolean equals(final Object peer_) {
    if (!(peer_ instanceof ArcFileHeaderItem)) {
      return false;
    }
    if (peer_ == this) {
      return true;
    }
    ArcFileHeaderItem peer = (ArcFileHeaderItem) peer_;
    boolean ret = __validFields.equals(peer.__validFields);
    if (!ret) return ret;
    if (__validFields.get(Field_ITEMKEY)) {
      ret = itemKey.equals(peer.itemKey);
      if (!ret) return ret;
    }
    if (__validFields.get(Field_ITEMVALUE)) {
      ret = itemValue.equals(peer.itemValue);
      if (!ret) return ret;
    }
    return ret;
  }
  // clone implementation 
  @SuppressWarnings("unchecked")
  public final Object clone() throws CloneNotSupportedException {
    ArcFileHeaderItem other = new ArcFileHeaderItem();
    other.__validFields.or(this.__validFields);
    if (__validFields.get(Field_ITEMKEY)){
      other.itemKey= new TextBytes(this.itemKey);
    }
    if (__validFields.get(Field_ITEMVALUE)){
      other.itemValue= new TextBytes(this.itemValue);
    }
    return other;
  }
  // merge implementation 
  @SuppressWarnings("unchecked")
  public final void merge(Object peer_) throws CloneNotSupportedException  {
    ArcFileHeaderItem peer = (ArcFileHeaderItem) peer_;
    __validFields.or(peer.__validFields);
    if (peer.__validFields.get(Field_ITEMKEY)){
      this.itemKey= new TextBytes(peer.itemKey);
    }
    if (peer.__validFields.get(Field_ITEMVALUE)){
      this.itemValue= new TextBytes(peer.itemValue);
    }
  }
  // hashCode implementation 
  public final int hashCode() {
    int result = 1;
    result = MurmurHash.hash(itemKey.getBytes(),itemKey.getOffset(),itemKey.getLength(),result);
    result = MurmurHash.hash(itemValue.getBytes(),itemValue.getOffset(),itemValue.getLength(),result);
    return result;
  }
}
